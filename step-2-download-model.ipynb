{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c9fc31-b77e-4007-8901-d186024675cd",
   "metadata": {},
   "source": [
    "# Step 2: Download and Convert the Base Model\n",
    "\n",
    "This notebook performs the preparatory tasks needed for obtaining the base model that we will use for fine-tuning.\n",
    "\n",
    "## Setup and Requirements\n",
    "Before proceeding, you need to install one dependency to follow along. Execute the following cell before getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9f6f9-b0c3-4c15-92d4-5c7ff0e5a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccfc187",
   "metadata": {},
   "source": [
    "Please run the following cell to incorporate patches required for this hackathon material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11920d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -O /opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron/gemma2/gemma2_modules.py \\\n",
    "        https://raw.githubusercontent.com/NVIDIA/NeMo/721f9101f92c9dc3976689b2bf45bad1d5075d07/nemo/collections/nlp/models/language_modeling/megatron/gemma2/gemma2_modules.py\n",
    "\n",
    "\n",
    "wget -O /opt/NeMo/scripts/checkpoint_converters/convert_gemma2_hf_to_nemo.py \\\n",
    "        https://raw.githubusercontent.com/NVIDIA/NeMo/721f9101f92c9dc3976689b2bf45bad1d5075d07/scripts/checkpoint_converters/convert_gemma2_hf_to_nemo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74332120-9e1a-4a08-96bc-b56308d3eeb7",
   "metadata": {},
   "source": [
    "\n",
    "### HuggingFace API Key\n",
    "\n",
    "Next, please specify your HuggingFace API token. This token will be used for downloading the base model.\n",
    "If you do not have an access token, follow [this tutorial](https://huggingface.co/docs/hub/en/security-tokens#how-to-manage-user-access-tokens) to generate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your HuggingFace token here.\n",
    "HF_TOKEN=\"<YOUR_HF_TOKEN>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb293b5",
   "metadata": {},
   "source": [
    "## Base Model Specificaions\n",
    "\n",
    "For this work, we will use the Gemma-2-2B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use = \"google/gemma-2-2b\"\n",
    "model_name = model_to_use.split('/')[-1].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcaaeb-59d6-4a71-a4fe-eb577a6b439c",
   "metadata": {},
   "source": [
    "---\n",
    "## Download the Base Model from Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ad3a5-3050-407e-bcd4-3644d638450a",
   "metadata": {},
   "source": [
    "Gemma 2 is a gated model on Hugging Face. To download it, you must first request access to the model by following the link [here](https://huggingface.co/google/gemma-2-2b-it)\n",
    "\n",
    "After access has been granted, run the following cell to download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e353d3-9232-4538-968d-882ea44ccd15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "# Download the model\n",
    "login(token=HF_TOKEN)\n",
    "snapshot_download(repo_id=model_to_use, local_dir=f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be275449",
   "metadata": {},
   "source": [
    "---\n",
    "## Convert the Model to `.nemo` Format\n",
    "\n",
    "To use the downloaded model with the NeMo Framework, we need to convert the checkpoint to the NeMo format. This is done thorugh a helper script that is already provided in the NeMo Framework container.\n",
    "\n",
    "> NOTE: The conversion is a one-time process and may take some time to finish.\n",
    "\n",
    "To begin the conversion process, execute the following cell.\n",
    "\n",
    "> NOTE: If you encounter any errors during the conversion process, a log file named `model_conversion.log` will be produced in the current working directory. Please include this file when filing support requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd666e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "command = f\"\"\"\n",
    "python3 /opt/NeMo/scripts/checkpoint_converters/convert_gemma2_hf_to_nemo.py \\\\\n",
    "    --input_name_or_path ./models/{model_name} \\\\\n",
    "    --tokenizer_path ./models/{model_name}/tokenizer.model \\\\\n",
    "    --output_path ./models/{model_name}.nemo \\\\\n",
    "    --run_verification\n",
    "\"\"\"\n",
    "\n",
    "# The log file to capture any messages or errors from the conversion process\n",
    "log_filename = \"model_conversion.log\"\n",
    "\n",
    "if os.path.exists(log_filename):\n",
    "    os.remove(log_filename)\n",
    "\n",
    "print(\"Model conversion started. This will take some time...\")\n",
    "process = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "# Did the conversion process succeed?\n",
    "if process.returncode == 0:\n",
    "    print(\"Model conversion completed successfully!\")\n",
    "else:\n",
    "    # Write the logs to a file\n",
    "    with open(log_filename, \"w\") as f:\n",
    "        f.write(process.stdout)\n",
    "\n",
    "    print(f\"Model conversion failed!\")\n",
    "    print(f\"{'#'*80}\\nLogs:\\n{'#'*80}\")\n",
    "    print(process.stdout)\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    print(f\"Logs also saved to '{os.path.abspath(log_filename)}'.\\nPlease share this file with us if you need help debugging the issue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8c3f4",
   "metadata": {},
   "source": [
    "---\n",
    "# Freeing Memory and Other Resources\n",
    "\n",
    "Before moving to the next notebook, please execute the following cell to free up all the allocated resources to avoid running into out-of-memory or other issues.\n",
    "\n",
    "Alternatively, please restart the kernel by navigating to `Kernel > Restart Kernel` (if using Jypyter notebook), or clicking the `Restart` button in VS Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c590d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
