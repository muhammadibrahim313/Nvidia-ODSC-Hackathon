{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c9fc31-b77e-4007-8901-d186024675cd",
   "metadata": {},
   "source": [
    "# Step 3: Training a LoRA Adapter\n",
    "\n",
    "This notebook performs the preparatory tasks needed for obtaining the base model that we will use for fine-tuning.\n",
    "\n",
    "This notebook showcases performing LoRA fine-tuning on the dataset that we curated in step 1.\n",
    "\n",
    "## Setup and Requirements\n",
    "Before proceeding, please make ensure you have completed the notebooks for steps 1 and 2. You will need to install one dependency to follow along. Execute the following cell before getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffbcf2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'jupyter0-k7ilcamcx.brevlab.com': No scheme supplied. Perhaps you meant https://jupyter0-k7ilcamcx.brevlab.com?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \n\u001b[0;32m      2\u001b[0m headers \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCF-Access-Client-Id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf7254c3f8c959c2e6295b2b1a7d6d182.access\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCF-Access-Client-Secret\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma69ceadb6d951e670c073cc6525c549512a3ec66a47827bd96aa163586ce3f47\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m } \n\u001b[1;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjupyter0-k7ilcamcx.brevlab.com\u001b[39m\u001b[38;5;124m'\u001b[39m, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[0;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[0;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_request(req)\n\u001b[0;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[0;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[0;32m    581\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 484\u001b[0m p\u001b[38;5;241m.\u001b[39mprepare(\n\u001b[0;32m    485\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[0;32m    486\u001b[0m     url\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m    487\u001b[0m     files\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mfiles,\n\u001b[0;32m    488\u001b[0m     data\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    489\u001b[0m     json\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mjson,\n\u001b[0;32m    490\u001b[0m     headers\u001b[38;5;241m=\u001b[39mmerge_setting(\n\u001b[0;32m    491\u001b[0m         request\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders, dict_class\u001b[38;5;241m=\u001b[39mCaseInsensitiveDict\n\u001b[0;32m    492\u001b[0m     ),\n\u001b[0;32m    493\u001b[0m     params\u001b[38;5;241m=\u001b[39mmerge_setting(request\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams),\n\u001b[0;32m    494\u001b[0m     auth\u001b[38;5;241m=\u001b[39mmerge_setting(auth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth),\n\u001b[0;32m    495\u001b[0m     cookies\u001b[38;5;241m=\u001b[39mmerged_cookies,\n\u001b[0;32m    496\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mmerge_hooks(request\u001b[38;5;241m.\u001b[39mhooks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks),\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\models.py:367\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_url(url, params)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[1;32mc:\\Users\\RC\\miniconda3\\envs\\ML_Python\\Lib\\site-packages\\requests\\models.py:438\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m     )\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'jupyter0-k7ilcamcx.brevlab.com': No scheme supplied. Perhaps you meant https://jupyter0-k7ilcamcx.brevlab.com?"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "headers = { \n",
    "'CF-Access-Client-Id': 'f7254c3f8c959c2e6295b2b1a7d6d182.access', \n",
    "'CF-Access-Client-Secret': 'a69ceadb6d951e670c073cc6525c549512a3ec66a47827bd96aa163586ce3f47', \n",
    "} \n",
    "\n",
    "response = requests.get('jupyter0-k7ilcamcx.brevlab.com', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782f63e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9f6f9-b0c3-4c15-92d4-5c7ff0e5a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8e64b",
   "metadata": {},
   "source": [
    "Let's also specify the base model name that we will use for fine-tuning. This should be the same model you downloaded/converted in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2328694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use = \"google/gemma-2-2b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccfc187",
   "metadata": {},
   "source": [
    "---\n",
    "# Sanity Checking\n",
    "\n",
    "Let's do a quick sanity check to ensure we have all the pieces needed before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11920d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_name = model_to_use.split('/')[-1].lower()\n",
    "\n",
    "# The path to the model checkpoint, and also the data directory containing the training, validation, and test data.\n",
    "nemo_model_fp = os.path.abspath(f\"models/{model_name}.nemo\")\n",
    "data_dir = \"data/split\"\n",
    "\n",
    "# The directory where the results will be stored.\n",
    "result_dir = os.path.abspath(\"results\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Sanity checks\n",
    "assert os.path.exists(nemo_model_fp), f\"The model checkpoint at '{nemo_model_fp}' does not exist. Please ensure the model was downloaded successfully.\"\n",
    "assert os.path.exists(data_dir), f\"The data directory '{data_dir}' does not exist. Please ensure the data was prepared successfully.\"\n",
    "\n",
    "train_fp = os.path.abspath(f\"{data_dir}/train.jsonl\")\n",
    "val_fp = os.path.abspath(f\"{data_dir}/val.jsonl\")\n",
    "\n",
    "# Sanity checks\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure the data was prepared successfully.\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure the data was prepared successfully.\"\n",
    "\n",
    "#\n",
    "# Set the environment variables (needed for executing the next cell)\n",
    "#\n",
    "%env BASE_MODEL=$nemo_model_fp\n",
    "%env DATA_DIR=$data_dir\n",
    "%env TRAIN_DS=$train_fp\n",
    "%env VAL_DS=$val_fp\n",
    "%env RESULT_DIR=$result_dir\n",
    "\n",
    "print(f\"\\n{'#'*80}\")\n",
    "print(\"All checks passed. You are ready to go!\")\n",
    "print(f\"    Base model file: {nemo_model_fp}\")\n",
    "print(f\"    Data directory: {data_dir}\")\n",
    "print(f\"    Results: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d658d64",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Training\n",
    "\n",
    "With all the sanity checks passing, it is time to start model training.\n",
    "\n",
    "> NOTE: Running the following cell will remove any previously trained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4df27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "SCHEME=\"lora\"\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1\n",
    "\n",
    "# Clear up cached mem-map file\n",
    "rm $DATA_DIR/*idx*\n",
    "# Clean up prior results\n",
    "rm -r $RESULT_DIR\n",
    "\n",
    "torchrun --nproc_per_node=1 \\\n",
    "/opt/NeMo/examples/nlp/language_modeling/tuning/megatron_gpt_finetuning.py \\\n",
    "    exp_manager.exp_dir=${RESULT_DIR} \\\n",
    "    exp_manager.explicit_log_dir=${RESULT_DIR} \\\n",
    "    trainer.devices=1 \\\n",
    "    trainer.num_nodes=1 \\\n",
    "    trainer.precision=bf16 \\\n",
    "    trainer.val_check_interval=200 \\\n",
    "    trainer.max_steps=1000 \\\n",
    "    trainer.gradient_clip_val=0.3 \\\n",
    "    model.megatron_amp_O2=True \\\n",
    "    ++model.mcore_gpt=True \\\n",
    "    model.tensor_model_parallel_size=${TP_SIZE} \\\n",
    "    model.pipeline_model_parallel_size=${PP_SIZE} \\\n",
    "    model.micro_batch_size=1 \\\n",
    "    model.global_batch_size=10 \\\n",
    "    model.restore_from_path=${BASE_MODEL} \\\n",
    "    model.data.train_ds.num_workers=0 \\\n",
    "    model.data.train_ds.add_bos=True \\\n",
    "    model.data.validation_ds.num_workers=0 \\\n",
    "    model.data.train_ds.file_names=[${TRAIN_DS}] \\\n",
    "    model.data.train_ds.concat_sampling_probabilities=[1.0] \\\n",
    "    model.data.validation_ds.file_names=[${VAL_DS}] \\\n",
    "    model.peft.peft_scheme=${SCHEME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a1d15",
   "metadata": {},
   "source": [
    "---\n",
    "# Inference and Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e1b57",
   "metadata": {},
   "source": [
    "To make a submission, run inference with your model on the test dataset at `data/split/submission.jsonl`.\n",
    "\n",
    "> NOTE: This dataset was generated as part of Step 1. Please ensure it exists before proceeding.\n",
    "\n",
    "In order to do this, set the variable pointing to your submission data file in the set below, then excute the final cell.\n",
    "\n",
    "The inference results will be written under `results/inference` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fp = os.path.abspath(f\"{data_dir}/submission.jsonl\")\n",
    "assert os.path.exists(test_fp), f\"The submission data at '{test_fp}' does not exist. Please ensure the data was prepared successfully.\"\n",
    "\n",
    "test_fp = os.path.abspath(test_fp)\n",
    "adapter_fp = f\"{result_dir}/checkpoints/megatron_gpt_peft_lora_tuning.nemo\"\n",
    "os.makedirs(f\"{result_dir}/inference\", exist_ok=True)\n",
    "\n",
    "print(f\"Inference set: {test_fp}\")\n",
    "print(f\"Trained adapter: {adapter_fp}\")\n",
    "test_filename = os.path.basename(test_fp)\n",
    "\n",
    "\n",
    "%env TEST_DS=$test_fp\n",
    "%env TEST_FP=$test_filename\n",
    "%env TRAINED_ADAPTER=$adapter_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# This is where the inference results will be stored.\n",
    "OUTPUT_DIR=\"results/inference/infer-$TEST_FP\"\n",
    "\n",
    "SCHEME=\"lora\"\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1\n",
    "\n",
    "# Clear up cached mem-map file\n",
    "rm $DATA_DIR/*idx*\n",
    "\n",
    "python /opt/NeMo/examples/nlp/language_modeling/tuning/megatron_gpt_generate.py \\\n",
    "    model.restore_from_path=${BASE_MODEL} \\\n",
    "    model.peft.restore_from_path=${TRAINED_ADAPTER} \\\n",
    "    trainer.devices=1 \\\n",
    "    trainer.num_nodes=1 \\\n",
    "    inference.greedy=True \\\n",
    "    model.data.test_ds.file_names=[${TEST_DS}] \\\n",
    "    model.data.test_ds.names=[\"infer\"] \\\n",
    "    model.data.test_ds.global_batch_size=16 \\\n",
    "    model.data.test_ds.micro_batch_size=1 \\\n",
    "    model.data.test_ds.tokens_to_generate=32 \\\n",
    "    model.tensor_model_parallel_size=${TP_SIZE} \\\n",
    "    model.pipeline_model_parallel_size=${PP_SIZE} \\\n",
    "    model.data.test_ds.output_file_path_prefix=$OUTPUT_DIR \\\n",
    "    model.data.test_ds.write_predictions_to_file=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5e7ee",
   "metadata": {},
   "source": [
    "The results will be written under `results/inference`. Please send us this file for your final submission.\n",
    "\n",
    "Let's inspect a couple of lines from that file for sanity checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4726de",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat results/inference/infer-submission.jsonl_test_infer_inputs_preds_labels.jsonl | head -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58554da2",
   "metadata": {},
   "source": [
    "---\n",
    "# Freeing Memory and Other Resources\n",
    "\n",
    "As always, it is a good idea to free up all allocated resources when you are done. Please execute the following cell to do so.\n",
    "\n",
    "Alternatively, please restart the kernel by navigating to `Kernel > Restart Kernel` (if using Jypyter notebook), or clicking the `Restart` button in VS Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf196ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
